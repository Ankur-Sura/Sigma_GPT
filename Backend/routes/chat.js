// =============================================================================
//                     CHAT ROUTES - Conversation & Thread Management
// =============================================================================
/**
 * ðŸ“š WHAT IS THIS FILE?
 * ---------------------
 * This file handles all chat-related API endpoints:
 * 1. Creating and managing chat threads
 * 2. Sending messages and getting AI responses
 * 3. Global memory across threads
 * 
 * ðŸ”— ENDPOINTS IN THIS FILE:
 * --------------------------
 * GET    /api/thread           â†’ Get all threads (sidebar history)
 * GET    /api/thread/:threadId â†’ Get messages for a specific thread
 * DELETE /api/thread/:threadId â†’ Delete a thread
 * PATCH  /api/thread/:threadId â†’ Rename a thread
 * POST   /api/chat             â†’ Send message, get AI response
 * POST   /api/rag-chat         â†’ Send question to RAG service (legacy)
 * 
 * ðŸ“Œ KEY CONCEPT - THREADS:
 * -------------------------
 * A "thread" = One conversation (like a ChatGPT chat)
 * Each thread has:
 * - threadId: Unique identifier (UUID)
 * - title: Display name in sidebar
 * - messages: Array of {role, content} objects
 * 
 * ðŸ“Œ INTERVIEW TIP:
 * -----------------
 * "I use MongoDB to persist chat threads. Each thread stores the full
 *  conversation history, and I also maintain a global memory thread
 *  for cross-thread context (like ChatGPT's memory feature)."
 */

import express from "express";
// ðŸ“– Express framework for creating routes

import Thread from "../models/Thread.js";
// ðŸ“– Mongoose model for Thread documents
// Defines schema: threadId, title, messages[], timestamps

import getOpenAIAPIResponse from "../utils/openai.js";
// ðŸ“– Utility function that calls OpenAI API
// Handles system prompt, message history, API call

const router = express.Router();
// ðŸ“– Creates a modular router
// Allows us to define routes here and mount them in server.js

const AI_SERVICE_URL = process.env.AI_SERVICE_URL || "http://localhost:8000";
// ðŸ“– Base URL for Python AI service
// ðŸ“Œ Why a separate service?
// - Python has better AI/ML libraries (LangChain, etc.)
// - Node.js handles web requests, Python handles AI logic
// - Microservices pattern: each service does one thing well

// =============================================================================
//                         TEST ENDPOINT (Development)
// =============================================================================

router.post("/test", async(req, res) => {
    // ðŸ“– Test endpoint for verifying MongoDB connection
    // Creates a sample thread to test database write operations
    try {
        const thread = new Thread({
            threadId: "abc",
            title: "Testing New Thread2"
        });

        const response = await thread.save();
        // ðŸ“– .save() inserts the document into MongoDB
        res.send(response);
    } catch(err) {
        console.log(err);
        res.status(500).json({error: "Failed to save in DB"});
    }
});


// =============================================================================
//                         GET ALL THREADS (Sidebar)
// =============================================================================
/**
 * ðŸ“– GET /api/thread
 * ------------------
 * Returns all chat threads for the sidebar history.
 * 
 * Used by: Frontend Sidebar component
 * When: On page load and after creating new chats
 * 
 * ðŸ“Œ WHY SORT BY updatedAt?
 * Most recent chats appear at the top (like ChatGPT)
 */

router.get("/thread", async(req, res) => {
    try {
        const threads = await Thread.find({}).sort({updatedAt: -1});
        // ðŸ“– Thread.find({}) â†’ Get all documents
        // ðŸ“– .sort({updatedAt: -1}) â†’ Sort descending (newest first)
        // ðŸ“Œ -1 = descending, 1 = ascending
        
        res.json(threads);
    } catch(err) {
        console.log(err);
        res.status(500).json({error: "Failed to fetch threads"});
    }
});


// =============================================================================
//                    GET SINGLE THREAD MESSAGES (Load Chat)
// =============================================================================
/**
 * ðŸ“– GET /api/thread/:threadId
 * ----------------------------
 * Returns messages for a specific thread WITH PAGINATION.
 * 
 * Used by: Frontend when user clicks a chat in sidebar
 * Returns: { messages: [...], hasMore: boolean, totalMessages: number, page: number }
 * 
 * ðŸ“Œ URL PARAMETER:
 * :threadId is a route parameter, accessed via req.params.threadId
 * 
 * ðŸ“Œ QUERY PARAMETERS (for pagination):
 * ?page=1&limit=20
 * - page: Which page to load (1 = most recent messages)
 * - limit: How many messages per page
 * 
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ðŸ“– PAGINATION EXPLAINED - IMPORTANT FOR INTERVIEWS!
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * 
 * ðŸ¤” WHAT IS PAGINATION?
 * ----------------------
 * Pagination means loading data in small "pages" or chunks instead of all at once.
 * 
 * Example: A chat has 500 messages
 * WITHOUT pagination: Load all 500 â†’ Slow! (takes 500ms+)
 * WITH pagination:    Load last 20 â†’ Fast! (takes 50ms)
 *                     Load next 20 when user scrolls up
 * 
 * ðŸ“Š VISUAL EXAMPLE:
 * ------------------
 * Imagine messages stored like this (index 0 = oldest, index 99 = newest):
 * 
 * [msg0, msg1, msg2, ... msg80, msg81, msg82, ... msg97, msg98, msg99]
 *   â†‘                            â†‘                              â†‘
 * Oldest                      Middle                         Newest
 * (index 0)                                                (index 99)
 * 
 * PAGE 1 (limit=20): Returns msg80 to msg99 (most recent 20)
 * PAGE 2 (limit=20): Returns msg60 to msg79 (next 20 older)
 * PAGE 3 (limit=20): Returns msg40 to msg59 (next 20 older)
 * ... and so on
 * 
 * ðŸ”¢ THE MATH:
 * ------------
 * totalMessages = 100 (total messages in thread)
 * limit = 20 (messages per page)
 * page = 1 (first page = most recent)
 * 
 * endIndex = totalMessages - ((page - 1) * limit)
 *          = 100 - ((1 - 1) * 20)
 *          = 100 - 0
 *          = 100 (exclusive, so up to index 99)
 * 
 * startIndex = max(0, endIndex - limit)
 *            = max(0, 100 - 20)
 *            = 80
 * 
 * Result: slice(80, 100) â†’ messages from index 80 to 99 (the last 20)
 * 
 * ðŸ“± WHY LOAD NEWEST FIRST?
 * -------------------------
 * Users want to see recent messages immediately!
 * - Open chat â†’ See latest messages (Page 1)
 * - Scroll UP â†’ Load older messages (Page 2, 3, ...)
 * - This is how WhatsApp, Telegram, ChatGPT work!
 * 
 * ðŸ“Œ INTERVIEW TIP:
 * -----------------
 * "I implemented pagination for chat history to improve load times.
 *  Instead of loading all messages at once, I load the 20 most recent
 *  first, then load older messages when the user scrolls up. This
 *  reduces initial load time from ~500ms to ~50ms."
 */

router.get("/thread/:threadId", async(req, res) => {
    const {threadId} = req.params;
    // ðŸ“– Destructure threadId from URL parameters
    // URL: /api/thread/abc123 â†’ threadId = "abc123"

    // =========================================================================
    // PAGINATION PARAMETERS FROM QUERY STRING
    // =========================================================================
    /**
     * ðŸ“– QUERY PARAMETERS:
     * URL: /api/thread/abc123?page=1&limit=20
     * 
     * req.query = { page: "1", limit: "20" }
     * 
     * ðŸ“Œ NOTE: Query params are always strings!
     * That's why we use parseInt() to convert to numbers.
     * 
     * ðŸ“Œ DEFAULT VALUES:
     * - page=1: Start with most recent messages
     * - limit=20: Load 20 messages at a time (good balance of speed vs content)
     */
    const page = parseInt(req.query.page) || 1;
    // ðŸ“– parseInt("1") â†’ 1 (number)
    // ðŸ“– parseInt(undefined) â†’ NaN, so || 1 gives us default of 1
    
    const limit = parseInt(req.query.limit) || 20;
    // ðŸ“– How many messages to return per page
    // ðŸ“Œ 20 is a good default: not too few, not too many

    try {
        const thread = await Thread.findOne({threadId});
        // ðŸ“– findOne() returns the first matching document
        // ðŸ“Œ Different from find() which returns an array

        if(!thread) {
            return res.status(404).json({error: "Thread not found"});
            // ðŸ“– Added "return" to prevent further execution!
        }

        // =====================================================================
        // CALCULATE PAGINATION INDICES
        // =====================================================================
        /**
         * ðŸ“– THE PAGINATION MATH EXPLAINED:
         * 
         * SCENARIO: 100 messages, limit=20, page=1
         * 
         * totalMessages = 100
         * 
         * Step 1: Calculate where to END
         * endIndex = totalMessages - ((page - 1) * limit)
         *          = 100 - ((1 - 1) * 20)
         *          = 100 - 0
         *          = 100
         * 
         * Step 2: Calculate where to START
         * startIndex = max(0, endIndex - limit)
         *            = max(0, 100 - 20)
         *            = max(0, 80)
         *            = 80
         * 
         * Step 3: Slice the array
         * messages.slice(80, 100) â†’ Returns messages at index 80-99
         * 
         * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         * 
         * SCENARIO: 100 messages, limit=20, page=2
         * 
         * endIndex = 100 - ((2 - 1) * 20)
         *          = 100 - 20
         *          = 80
         * 
         * startIndex = max(0, 80 - 20)
         *            = 60
         * 
         * messages.slice(60, 80) â†’ Returns messages at index 60-79
         * 
         * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         * 
         * SCENARIO: 100 messages, limit=20, page=5 (last page)
         * 
         * endIndex = 100 - ((5 - 1) * 20)
         *          = 100 - 80
         *          = 20
         * 
         * startIndex = max(0, 20 - 20)
         *            = max(0, 0)
         *            = 0
         * 
         * messages.slice(0, 20) â†’ Returns messages at index 0-19 (oldest)
         * hasMore = false (startIndex is 0, no more messages)
         */
        
        const totalMessages = thread.messages.length;
        // ðŸ“– Total number of messages in this thread
        
        const endIndex = totalMessages - ((page - 1) * limit);
        // ðŸ“– Where to stop slicing (exclusive)
        // ðŸ“Œ For page 1: endIndex = total (get from end)
        // ðŸ“Œ For page 2: endIndex = total - limit (skip recent, get older)
        
        const startIndex = Math.max(0, endIndex - limit);
        // ðŸ“– Where to start slicing
        // ðŸ“– Math.max(0, ...) ensures we don't go negative
        // ðŸ“Œ If endIndex - limit < 0, we're on the last page of old messages
        
        const messages = thread.messages.slice(startIndex, endIndex);
        // ðŸ“– Array.slice(start, end) returns elements from start to end-1
        // ðŸ“Œ This gives us the "page" of messages we want
        
        const hasMore = startIndex > 0;
        // ðŸ“– Are there more (older) messages to load?
        // ðŸ“Œ If startIndex is 0, we've reached the oldest messages
        // ðŸ“Œ Frontend uses this to know if it should show "Load More" option

        // =====================================================================
        // SEND PAGINATED RESPONSE
        // =====================================================================
        /**
         * ðŸ“– RESPONSE STRUCTURE:
         * {
         *   messages: [...],      // The page of messages
         *   hasMore: true/false,  // Are there older messages?
         *   totalMessages: 100,   // Total count (for UI info)
         *   page: 1               // Current page number
         * }
         * 
         * ðŸ“Œ WHY RETURN hasMore?
         * Frontend needs to know if it should:
         * - Show "scroll to load more" indicator
         * - Make another request when user scrolls up
         * - Stop requesting when all messages are loaded
         */
        res.json({
            messages,
            hasMore,
            totalMessages,
            page
        });
        
    } catch(err) {
        console.log(err);
        res.status(500).json({error: "Failed to fetch chat"});
    }
});


// =============================================================================
//                        DELETE THREAD (Delete Chat)
// =============================================================================
/**
 * ðŸ“– DELETE /api/thread/:threadId
 * --------------------------------
 * Deletes a chat thread from the database.
 * 
 * Used by: Frontend trash icon in sidebar
 * 
 * ðŸ“Œ HTTP DELETE:
 * RESTful convention for removing resources
 */

router.delete("/thread/:threadId", async (req, res) => {
    const {threadId} = req.params;

    try {
        const deletedThread = await Thread.findOneAndDelete({threadId});
        // ðŸ“– findOneAndDelete() finds and removes in one operation
        // Returns the deleted document (or null if not found)

        if(!deletedThread) {
            res.status(404).json({error: "Thread not found"});
        }

        res.status(200).json({success : "Thread deleted successfully"});

    } catch(err) {
        console.log(err);
        res.status(500).json({error: "Failed to delete thread"});
    }
});


// =============================================================================
//                      RENAME THREAD (Edit Chat Title)
// =============================================================================
/**
 * ðŸ“– PATCH /api/thread/:threadId
 * ------------------------------
 * Updates the title of a chat thread.
 * 
 * Used by: Frontend edit icon in sidebar
 * Body: { "title": "New Title" }
 * 
 * ðŸ“Œ WHY PATCH vs PUT?
 * - PATCH = Partial update (only title)
 * - PUT = Full replacement (all fields)
 * We only update title, so PATCH is correct
 */

router.patch("/thread/:threadId", async (req, res) => {
    const {threadId} = req.params;
    const {title} = req.body || {};

    if(!title) {
        return res.status(400).json({error: "Missing title"});
        // ðŸ“– 400 = Bad Request (client error)
    }

    try {
        const updated = await Thread.findOneAndUpdate(
            {threadId},                        // ðŸ“– Filter: which document to update
            {title, updatedAt: new Date()},    // ðŸ“– Update: new values
            {new: true}                        // ðŸ“– Option: return updated doc (not original)
        );
        // ðŸ“Œ {new: true} is important!
        // Without it, you get the OLD document before update
        
        if(!updated) {
            return res.status(404).json({error: "Thread not found"});
        }
        return res.json({success: true, threadId, title: updated.title});
    } catch (err) {
        console.log(err);
        return res.status(500).json({error: "Failed to update thread title"});
    }
});

// =============================================================================
//                     MAIN CHAT ENDPOINT (Send Message)
// =============================================================================
/**
 * ðŸ“– POST /api/chat
 * -----------------
 * The main chat endpoint - handles sending messages and getting AI responses.
 * 
 * Body: { "threadId": "uuid", "message": "Hello!" }
 * Returns: { "reply": "AI response..." }
 * 
 * ðŸ“Œ KEY FEATURES:
 * 1. Creates new thread if doesn't exist
 * 2. Maintains conversation history
 * 3. Global memory across threads (like ChatGPT's memory!)
 * 
 * ðŸ“Œ INTERVIEW TIP:
 * "My chat system maintains both thread-specific history and global memory.
 *  This allows the AI to remember user preferences across conversations,
 *  similar to ChatGPT's memory feature."
 */

router.post("/chat", async(req, res) => {
    const {threadId, message} = req.body;
    // ðŸ“– Destructure from request body
    // threadId: UUID for this conversation
    // message: User's message text

    if(!threadId || !message) {
        res.status(400).json({error: "missing required fields"});
        // ðŸ“– 400 = Bad Request (validation error)
    }

    try {
        // =================================================================
        // STEP 1: Load or Create Thread
        // =================================================================
        let thread = await Thread.findOne({threadId});
        // ðŸ“– Try to find existing thread

        const globalThreadId = "global-shared";
        let globalThread = await Thread.findOne({threadId: globalThreadId});
        // ðŸ“– Global thread stores memory shared across ALL threads
        // ðŸ“Œ This is like ChatGPT's "Memory" feature!

        if(!thread) {
            // Create new thread if first message
            thread = new Thread({
                threadId,
                title: message,  // ðŸ“– First message becomes thread title
                messages: [{role: "user", content: message}]
            });
        } else {
            // Add message to existing thread
            thread.messages.push({role: "user", content: message});
        }

        // =================================================================
        // STEP 2: Build Message History (Global + Local)
        // =================================================================
        // ðŸ“Œ WHY MERGE HISTORIES?
        // Global history: User preferences, name, facts from other threads
        // Local history: Current conversation context
        // Together: AI knows both user preferences AND current context
        
        const globalHistory = (globalThread?.messages || []).slice(-20);
        // ðŸ“– Last 20 messages from global memory

        const localHistory = (thread.messages || []).slice(-20);
        // ðŸ“– Last 20 messages from current thread

        const mergedHistory = [...globalHistory, ...localHistory];
        // ðŸ“– Spread operator combines both arrays
        
        const assistantReply = await getOpenAIAPIResponse(message, mergedHistory.slice(0, -1));
        // ðŸ“– Call OpenAI with full history
        // ðŸ“Œ slice(0, -1): Exclude last message (already in prompt)

        // =================================================================
        // STEP 3: Save Response to Thread
        // =================================================================
        thread.messages.push({role: "assistant", content: assistantReply});
        thread.updatedAt = new Date();
        // ðŸ“– Update timestamp so thread appears at top of sidebar

        await thread.save();
        // ðŸ“– Persist to MongoDB

        // =================================================================
        // STEP 4: Update Global Memory
        // =================================================================
        // ðŸ“Œ GLOBAL MEMORY PATTERN:
        // Everything said in ANY thread is also saved to global memory
        // This allows AI to remember user across threads
        
        if(!globalThread) {
            globalThread = new Thread({
                threadId: globalThreadId,
                title: "Global Memory",
                messages: []
            });
        }
        globalThread.messages.push({role: "user", content: message});
        globalThread.messages.push({role: "assistant", content: assistantReply});
        
        // ðŸ“– Trim to prevent unbounded growth
        if(globalThread.messages.length > 40) {
            globalThread.messages = globalThread.messages.slice(-40);
            // ðŸ“Œ Keep only last 40 messages (20 exchanges)
        }
        globalThread.updatedAt = new Date();
        await globalThread.save();

        res.json({reply: assistantReply});
    } catch(err) {
        console.log(err);
        res.status(500).json({error: "something went wrong"});
    }
});


// =============================================================================
//                       RAG CHAT ENDPOINT (Legacy)
// =============================================================================
/**
 * ðŸ“– POST /api/rag-chat
 * ---------------------
 * Forwards questions to Python RAG service for document-grounded answers.
 * 
 * Body: { "question": "What is...?" }
 * Returns: { "reply": "...", "context": "..." }
 * 
 * ðŸ“Œ RAG = Retrieval Augmented Generation
 * 1. Find relevant document chunks (retrieval)
 * 2. Give chunks to LLM as context (augmentation)
 * 3. LLM generates answer using that context (generation)
 * 
 * ðŸ“Œ NOTE: This is a legacy endpoint.
 * Current PDF Q&A uses /api/pdf-query in pdf.js instead.
 */

router.post("/rag-chat", async (req, res) => {
    const {question} = req.body;

    if(!question) {
        return res.status(400).json({error: "missing required fields"});
    }

    try {
        const response = await fetch(`${AI_SERVICE_URL}/rag/query`, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify({question})
        });
        // ðŸ“– Forward request to Python AI service
        // ðŸ“Œ This is the "Backend as Proxy" pattern:
        // Frontend â†’ Backend â†’ AI Service
        // Why? Keeps AI service URL hidden, adds auth, logging, etc.

        const data = await response.json();

        return res.json({reply: data.answer, context: data.context_used});
    } catch(err) {
        console.log(err);
        return res.status(500).json({error: "RAG service call failed"});
    }
});


// =============================================================================
//                              EXPORT ROUTER
// =============================================================================

export default router;
// ðŸ“– ES Module export (not CommonJS module.exports)
// Imported in server.js: import chatRoutes from "./routes/chat.js"


// =============================================================================
//                         SUMMARY FOR INTERVIEWS
// =============================================================================
/**
 * ðŸ“Œ ENDPOINTS SUMMARY:
 * 
 * | Method | Endpoint              | Purpose                    |
 * |--------|-----------------------|----------------------------|
 * | GET    | /api/thread           | Get all threads (sidebar)  |
 * | GET    | /api/thread/:id       | Get thread messages        |
 * | DELETE | /api/thread/:id       | Delete a thread            |
 * | PATCH  | /api/thread/:id       | Rename thread title        |
 * | POST   | /api/chat             | Send message, get reply    |
 * | POST   | /api/rag-chat         | Query with RAG context     |
 * 
 * ðŸ“Œ KEY CONCEPTS:
 * - Thread = One conversation (like ChatGPT chat)
 * - Global memory = Shared across all threads
 * - RESTful design: GET read, POST create, PATCH update, DELETE remove
 * - Mongoose for MongoDB operations
 * - Proxy pattern: Backend forwards to AI service
 */
